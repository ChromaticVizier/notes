### deepspeed Zero

ZeRO被分为了三个级别：

1. ZeRO1：对优化器状态进行拆分。显存消耗减少 4 倍，通信量与数据并行相同。
2. ZeRO2：在ZeRO1的基础上，对梯度进行拆分。显存消耗减少 8 倍，通信量与数据并行相同。
3. ZeRO3：在ZeRO2的基础上，对模型参数进行拆分。模型占用的显存被平均分配到每个 GPU 中，显存消耗量与数据并行的并行度成线性反比关系，但通信量会有些许增加。

![img](https://zerolovesea.github.io/images/zerodp.jpg)

#### Zero1

只有在梯度更新的时候才会使用梯度和优化器状态计算新参数。因此每个进程单独使用一段优化器状态，对各自进程的参数更新完之后，再把各个进程的模型参数合并形成完整的模型。



假设我们有 𝑁𝑑 个并行的进程，ZeRO-1 会将完整优化器的状态等分成 𝑁𝑑 份并储存在各个进程中。当反向传播完成之后，每个进程的优化器会对自己储存的优化器状态（包括Momentum、Variance 与 FP32 Master Parameters）进行计算与更新。更新过后的`Partitioned FP32 Master Parameters`会通过`All-gather`传回到各个进程中。完成一次完整的参数更新。



#### Zero2

第二阶段中对梯度进行了拆分，在一个Layer的梯度都被计算出来后： 梯度通过`All-reduce`进行聚合， 聚合后的梯度只会被某一个进程用来更新参数，因此其它进程上的这段梯度不再被需要，可以立马释放掉。



#### Zero3

模型的每一层都被切片，每个进程存储权重张量的一部分。在前向和后向传播过程中（每个进程仍然看到不同的微批次数据），不同的进程交换它们所拥有的部分（按需进行参数通信），并计算激活函数和梯度。

初始化的时候。ZeRO3将一个模型中每个子层中的参数分片放到不同进程中，训练过程中，每个进程进行正常的正向/反向传播，然后通过`All-gather`进行汇总，构建成完整的模型。
